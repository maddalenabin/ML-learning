{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict how many medals the country is going to win in the next Olympic games. \\\n",
    "In this notebook I want to implement the functions for the linear regression and the cost function myself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "See notebook `02-libear-regression-sklearn.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>events</th>\n",
       "      <th>athletes</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>medals</th>\n",
       "      <th>prev_medals</th>\n",
       "      <th>prev_3_medals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1964</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>64.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1968</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23.2</td>\n",
       "      <td>170.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1972</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>168.3</td>\n",
       "      <td>63.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1980</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>23.6</td>\n",
       "      <td>168.4</td>\n",
       "      <td>63.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>170.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  team      country  year  events  athletes   age  height  weight  medals  \\\n",
       "0  AFG  Afghanistan  1964       8         8  22.0   161.0    64.2       0   \n",
       "1  AFG  Afghanistan  1968       5         5  23.2   170.2    70.0       0   \n",
       "2  AFG  Afghanistan  1972       8         8  29.0   168.3    63.8       0   \n",
       "3  AFG  Afghanistan  1980      11        11  23.6   168.4    63.2       0   \n",
       "4  AFG  Afghanistan  2004       5         5  18.6   170.8    64.8       0   \n",
       "\n",
       "   prev_medals  prev_3_medals  \n",
       "0          0.0            0.0  \n",
       "1          0.0            0.0  \n",
       "2          0.0            0.0  \n",
       "3          0.0            0.0  \n",
       "4          0.0            0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/teams.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>athletes</th>\n",
       "      <th>age</th>\n",
       "      <th>medals</th>\n",
       "      <th>prev_medals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1964</td>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1968</td>\n",
       "      <td>5</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1972</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1980</td>\n",
       "      <td>11</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  team  year  athletes   age  medals  prev_medals\n",
       "0  AFG  1964         8  22.0       0          0.0\n",
       "1  AFG  1968         5  23.2       0          0.0\n",
       "2  AFG  1972         8  29.0       0          0.0\n",
       "3  AFG  1980        11  23.6       0          0.0\n",
       "4  AFG  2004         5  18.6       0          0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_cols = ['team', 'year', 'athletes', 'age', 'medals', 'prev_medals']\n",
    "data = data[select_cols]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team             0\n",
       "year             0\n",
       "athletes         0\n",
       "age              0\n",
       "medals           0\n",
       "prev_medals    130\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many null values\n",
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team           0\n",
       "year           0\n",
       "athletes       0\n",
       "age            0\n",
       "medals         0\n",
       "prev_medals    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns with NaNs\n",
    "data = data.dropna()\n",
    "\n",
    "# check that the command was correct\n",
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data[\"year\"] < 2012].copy()\n",
    "test = data[data[\"year\"] >= 2012].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples is:  (1609, 6)\n",
      "The number of testing examples is:  (405, 6)\n",
      "Fraction of tesing exmamples:  0.201\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of training examples is: \", train.shape)\n",
    "print(\"The number of testing examples is: \", test.shape)\n",
    "print(\"Fraction of tesing exmamples: \", round(test.shape[0]/data.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>athletes</th>\n",
       "      <th>age</th>\n",
       "      <th>medals</th>\n",
       "      <th>prev_medals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1964</td>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1968</td>\n",
       "      <td>5</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1972</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>1980</td>\n",
       "      <td>11</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  team  year  athletes   age  medals  prev_medals\n",
       "0  AFG  1964         8  22.0       0          0.0\n",
       "1  AFG  1968         5  23.2       0          0.0\n",
       "2  AFG  1972         8  29.0       0          0.0\n",
       "3  AFG  1980        11  23.6       0          0.0\n",
       "4  AFG  2004         5  18.6       0          0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_train: <class 'pandas.core.frame.DataFrame'>\n",
      "First five elements of x_train are:\n",
      "    athletes  prev_medals\n",
      "0         8          0.0\n",
      "1         5          0.0\n",
      "2         8          0.0\n",
      "3        11          0.0\n",
      "4         5          0.0\n",
      "Type of y_train: <class 'pandas.core.frame.DataFrame'>\n",
      "First five elements of y_train are:\n",
      "    medals\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n"
     ]
    }
   ],
   "source": [
    "x_train = train[['athletes', 'prev_medals']]\n",
    "y_train = train[['medals']]\n",
    "\n",
    "# print x_train\n",
    "print(\"Type of x_train:\",type(x_train))\n",
    "print(\"First five elements of x_train are:\\n\", x_train[:5]) \n",
    "\n",
    "# print y_train\n",
    "print(\"Type of y_train:\",type(y_train))\n",
    "print(\"First five elements of y_train are:\\n\", y_train[:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (1609, 2)\n",
      "The shape of y_train is:  (1609, 1)\n",
      "Number of training examples (m): 1609\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of x_train is:', x_train.shape)\n",
    "print ('The shape of y_train is: ', y_train.shape)\n",
    "print ('Number of training examples (m):', len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent involves repeated steps to adjust the value of your parameter $(w,b)$ to gradually get a smaller and smaller cost $J(w,b)$.\n",
    "- At each step of gradient descent, it will be helpful for you to monitor your progress by computing the cost $J(w,b)$ as $(w,b)$ gets updated. \n",
    "- In this section, you will implement a function to calculate $J(w,b)$ so that you can check the progress of your gradient descent implementation.\n",
    "\n",
    "#### Cost function\n",
    "For one variable, the cost function for linear regression $J(w,b)$ is defined as\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$$ \n",
    "\n",
    "- You can think of $f_{w,b}(x^{(i)})$ as the model's prediction of your restaurant's profit, as opposed to $y^{(i)}$, which is the actual profit that is recorded in the data.\n",
    "- $m$ is the number of training examples in the dataset\n",
    "\n",
    "#### Model prediction\n",
    "\n",
    "- For linear regression with one variable, the prediction of the model $f_{w,b}$ for an example $x^{(i)}$ is representented as:\n",
    "\n",
    "$$ f_{w,b}(x^{(i)}) = wx^{(i)} + b$$\n",
    "\n",
    "This is the equation for a line, with an intercept $b$ and a slope $w$\n",
    "\n",
    "#### Implementation of Cost Function\n",
    "\n",
    "* Iterate over the training examples, and for each example, compute:\n",
    "    * The prediction of the model for that example \n",
    "    $$\n",
    "    f_{wb}(x^{(i)}) =  wx^{(i)} + b \n",
    "    $$\n",
    "   \n",
    "    * The cost for that example  $$cost^{(i)} =  (f_{wb} - y^{(i)})^2$$\n",
    "    \n",
    "\n",
    "* Return the total cost over all examples\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} cost^{(i)}$$\n",
    "  * Here, $m$ is the number of training examples and $\\sum$ is the summation operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1609"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (1609, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_m = .to_numpy()\n",
    "type(X_m), X_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    \n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        y = y.to_numpy()\n",
    "\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar   \n",
    "     \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (2,), b_init type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# choose initial guesses for b and w parameters\n",
    "b_init = 0\n",
    "w_init = np.ones(x_train.shape[1])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : [11428.72964574]\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost using our pre-chosen optimal parameters. \n",
    "cost = compute_cost(x_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`\n",
    "\n",
    "To demonstrate the dot product, we will implement prediction using (1) and (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (2,), x_vec value: [8. 0.]\n",
      "f_wb shape (), prediction: 8.0\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = x_train.to_numpy()[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict(x_vec,w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "In contrast to previous labs, $\\mathbf{w}$ and $\\mathbf{x}^{(i)}$ are vectors rather than scalars supporting multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    \n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        y = y.to_numpy()\n",
    "        \n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : [11428.72964574]\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost using our pre-chosen optimal parameters. \n",
    "cost = compute_cost(x_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    \n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        y = y.to_numpy()\n",
    "        \n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: [78.08328154]\n",
      "dj_dw at initial w,b: \n",
      " [23132.7992542   4218.19763828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xpvjr2rd5h37bdb655bsyz1r0000gp/T/ipykernel_7451/2030842061.py:27: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  dj_dw[j] = dj_dw[j] + err * X[i, j]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(x_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    \n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        y = y.to_numpy()\n",
    "\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        #if i% math.ceil(num_iters / 10) == 0:\n",
    "        #    print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/xpvjr2rd5h37bdb655bsyz1r0000gp/T/ipykernel_7451/2030842061.py:27: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  dj_dw[j] = dj_dw[j] + err * X[i, j]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# run gradient descent \u001b[39;00m\n\u001b[1;32m      8\u001b[0m w_final, b_final, J_hist \u001b[38;5;241m=\u001b[39m gradient_descent(x_train, y_train, initial_w, initial_b,\n\u001b[1;32m      9\u001b[0m                                                     compute_cost, compute_gradient, \n\u001b[1;32m     10\u001b[0m                                                     alpha, iterations)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb,w found by gradient descent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb_final\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw_final\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m m,_ \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(x_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(x_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost versus iteration  \n",
    "fig, ax1 = plt.subplots(1, 1, constrained_layout=True, figsize=(5, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax1.set_title(\"Cost vs. iteration\")\n",
    "ax1.set_ylabel('Cost')\n",
    "ax1.set_xlabel('iteration step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
